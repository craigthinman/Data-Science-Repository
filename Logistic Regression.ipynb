{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk through the end to end process of preparing, executing, and improving a logistic regression model to predict Titanic survivors. Logistic Regressions are useful for predicting outcomes that are binary like survive/not survive in the case of the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 33 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Survived            891 non-null    int64  \n",
      " 1   Age                 891 non-null    float64\n",
      " 2   Fare                891 non-null    float64\n",
      " 3   FamilySize          891 non-null    int64  \n",
      " 4   IsMother            891 non-null    int64  \n",
      " 5   IsMale              891 non-null    int64  \n",
      " 6   Deck_A              891 non-null    float64\n",
      " 7   Deck_B              891 non-null    float64\n",
      " 8   Deck_C              891 non-null    float64\n",
      " 9   Deck_D              891 non-null    float64\n",
      " 10  Deck_E              891 non-null    float64\n",
      " 11  Deck_F              891 non-null    float64\n",
      " 12  Deck_G              891 non-null    float64\n",
      " 13  Deck_Z              891 non-null    float64\n",
      " 14  Pclass_1            891 non-null    float64\n",
      " 15  Pclass_2            891 non-null    float64\n",
      " 16  Pclass_3            891 non-null    float64\n",
      " 17  Title_Lady          891 non-null    float64\n",
      " 18  Title_Master        891 non-null    float64\n",
      " 19  Title_Miss          891 non-null    float64\n",
      " 20  Title_Mr            891 non-null    float64\n",
      " 21  Title_Mrs           891 non-null    float64\n",
      " 22  Title_Officer       891 non-null    float64\n",
      " 23  Title_Sir           891 non-null    float64\n",
      " 24  Fare_Bin_very_low   891 non-null    float64\n",
      " 25  Fare_Bin_low        891 non-null    float64\n",
      " 26  Fare_Bin_high       891 non-null    float64\n",
      " 27  Fare_Bin_very_high  891 non-null    float64\n",
      " 28  Embarked_C          891 non-null    float64\n",
      " 29  Embarked_Q          891 non-null    float64\n",
      " 30  Embarked_S          891 non-null    float64\n",
      " 31  AgeState_Adult      891 non-null    float64\n",
      " 32  AgeState_Child      891 non-null    float64\n",
      "dtypes: float64(29), int64(4)\n",
      "memory usage: 236.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 32 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Age                 418 non-null    float64\n",
      " 1   Fare                418 non-null    float64\n",
      " 2   FamilySize          418 non-null    int64  \n",
      " 3   IsMother            418 non-null    int64  \n",
      " 4   IsMale              418 non-null    int64  \n",
      " 5   Deck_A              418 non-null    float64\n",
      " 6   Deck_B              418 non-null    float64\n",
      " 7   Deck_C              418 non-null    float64\n",
      " 8   Deck_D              418 non-null    float64\n",
      " 9   Deck_E              418 non-null    float64\n",
      " 10  Deck_F              418 non-null    float64\n",
      " 11  Deck_G              418 non-null    float64\n",
      " 12  Deck_Z              418 non-null    float64\n",
      " 13  Pclass_1            418 non-null    float64\n",
      " 14  Pclass_2            418 non-null    float64\n",
      " 15  Pclass_3            418 non-null    float64\n",
      " 16  Title_Lady          418 non-null    float64\n",
      " 17  Title_Master        418 non-null    float64\n",
      " 18  Title_Miss          418 non-null    float64\n",
      " 19  Title_Mr            418 non-null    float64\n",
      " 20  Title_Mrs           418 non-null    float64\n",
      " 21  Title_Officer       418 non-null    float64\n",
      " 22  Title_Sir           418 non-null    float64\n",
      " 23  Fare_Bin_very_low   418 non-null    float64\n",
      " 24  Fare_Bin_low        418 non-null    float64\n",
      " 25  Fare_Bin_high       418 non-null    float64\n",
      " 26  Fare_Bin_very_high  418 non-null    float64\n",
      " 27  Embarked_C          418 non-null    float64\n",
      " 28  Embarked_Q          418 non-null    float64\n",
      " 29  Embarked_S          418 non-null    float64\n",
      " 30  AgeState_Adult      418 non-null    float64\n",
      " 31  AgeState_Child      418 non-null    float64\n",
      "dtypes: float64(29), int64(3)\n",
      "memory usage: 107.8 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_file_path = r'C:\\Users\\Owner\\Desktop\\School\\Prog in Pyth C996\\Notebooks\\Data for LogReg\\train.csv'\n",
    "\n",
    "test_file_path = r'C:\\Users\\Owner\\Desktop\\School\\Prog in Pyth C996\\Notebooks\\Data for LogReg\\test.csv'\n",
    "\n",
    "train_df = pd.read_csv(filepath_or_buffer = train_file_path, index_col = 'PassengerId')\n",
    "test_df = pd.read_csv(filepath_or_buffer = test_file_path, index_col = 'PassengerId')\n",
    "\n",
    "display(train_df.info())\n",
    "display(test_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a model to predict the likeliness of surviving for the 418 entries in the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (891, 32) <class 'numpy.ndarray'> (891,)\n"
     ]
    }
   ],
   "source": [
    "# Most algotrhims expect numeric arrays. Making arrays for inputs - X (everything but Survived) and output y 'Survived'\n",
    "\n",
    "X = train_df.loc[:, 'Age':].to_numpy(dtype = 'float')\n",
    "y = train_df['Survived'].ravel()\n",
    "\n",
    "print(type(X), X.shape, type(y), y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 32) (712,)\n",
      "(179, 32) (179,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the train dataframe into train and test with 20% for testing and 80% for training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "712 rows in train and 179 in test. Next looking into how many positive class types are in the test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean survival in train: 0.383\n",
      "Mean survival in test: 0.385\n"
     ]
    }
   ],
   "source": [
    "# average survival in train and test sets\n",
    "print('Mean survival in train: {:.3f}'.format(np.mean(y_train)))\n",
    "print('Mean survival in test: {:.3f}'.format(np.mean(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar survival in the test and train sets ~39%. This is good because we ideally want them to be similar. One thing to note is the data is not balanced because of the low survival rates. Imbalance checks are good to carryout to see if there are any other steps in preparation needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a Baseline model is one of the first steps in creating a model. What it does is make a model that always outputs the majority class. In the case of the titanic dataset we observe that most did not survive. The baseline model will always output \"0\" for 'Survived'. This will provide an accuracy value that we can use to compare with the actual model accuracy. The final model accuracy should exceed the baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Baseline Model accuracy: 0.61\n"
     ]
    }
   ],
   "source": [
    "# create model -- specifying 'most frequent' in this case \"0\" - not survive\n",
    "model_dummy = DummyClassifier(strategy = 'most_frequent', random_state = 0)\n",
    "\n",
    "# train model\n",
    "model_dummy.fit(X_train, y_train)\n",
    "\n",
    "# Testing model\n",
    "print('Score for Baseline Model accuracy: {:.2f}'.format(model_dummy.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you predict not survive for each outcome you would be 61.5% accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports to calculate other performance metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the Baseline Model: 0.61\n"
     ]
    }
   ],
   "source": [
    "# We are able to calculate accuracy score in another way\n",
    "print('Accuracy for the Baseline Model: {:.2f}'.format(accuracy_score(y_test, model_dummy.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for the Baseline Model: \n",
      " [[110   0]\n",
      " [ 69   0]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print('Confusion Matrix for the Baseline Model: \\n {0}'.format(confusion_matrix(y_test, model_dummy.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for the Baseline Model: 0.00\n",
      "Recall for the Baseline Model: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Precision and Recall scores\n",
    "print('Precision for the Baseline Model: {:.2f}'.format(precision_score(y_test, model_dummy.predict(X_test))))\n",
    "print('Recall for the Baseline Model: {:.2f}'.format(recall_score(y_test, model_dummy.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Recall\n",
    "Accuracy tells one thing about the data but recall and precision can help tell more information about how the model is performing.\n",
    "\n",
    "The model predicted 179 non survivors out of what actually was 110 non survivors (True Negative) and 69 survivors (False Negative).\n",
    "\n",
    "The base model's precision in this case \"how many of the predicted survivors are actually survivors\" was 0% because we told it to only predict negative results. The base model's recall in this case \"how many of all the survivors were predicted\" was also 0% for the same reason.\n",
    "\n",
    "Definitions of an ideal value for one of these metrics in the real world changes like in the healthcare field. You could want recall to be 100% if you're trying to predict who has COVID-19 so that no one is incorrectly informed they are clear \"False Negative\"and go untreated. This case the accuracy and precision are okay to sacrifice to an extent.\n",
    "\n",
    "\n",
    "### Precision\n",
    "\n",
    "True Positives / (True Positives + False Positives)\n",
    "\n",
    "Correctly Predicted Survivors / (Correctly Predicted Survivors + Wrongly Predicted Survivors)\n",
    "\n",
    "\n",
    "### Recall\n",
    "True Positives / (True Positives + False Negatives)\n",
    "\n",
    "Correctly Predicted Survivors / (Correctly Predicted Survivors + Wrongly Predicted Non Survivors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the Logistic Regression: 0.83\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model_lr_1 = LogisticRegression(random_state = 0, max_iter = 1000) # 1000 max_iter to get rid of convergence error\n",
    "\n",
    "# train model\n",
    "model_lr_1.fit(X_train, y_train)\n",
    "\n",
    "# evalute model on test\n",
    "print('The accuracy for the Logistic Regression: {:.2f}'.format(model_lr_1.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the regression: 0.83\n",
      "Confusion Matrix for the regression: \n",
      " [[95 15]\n",
      " [15 54]]\n",
      "Precision - how good the model is at predicting survivors: 0.78\n",
      "Recall - out of all survivors how many were predicted: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Performance Metrics\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy for the regression: {:.2f}'.format(accuracy_score(y_test, model_lr_1.predict(X_test))))\n",
    "\n",
    "# Confusion Matrix\n",
    "print('Confusion Matrix for the regression: \\n {0}'.format(confusion_matrix(y_test, model_lr_1.predict(X_test))))\n",
    "\n",
    "# Precision and Recall scores\n",
    "print('Precision - how good the model is at predicting survivors: {:.2f}'.format(precision_score(y_test, model_lr_1.predict(X_test))))\n",
    "print('Recall - out of all survivors how many were predicted: {:.2f}'.format(recall_score(y_test, model_lr_1.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03269776,  0.00421194, -0.52678741,  0.63495839, -1.11331495,\n",
       "        -0.01565171, -0.30461563, -0.53291311,  0.39978536,  0.97618985,\n",
       "         0.2816164 , -0.28284974, -0.52112569,  0.58637084,  0.1314043 ,\n",
       "        -0.71733942,  0.22267681,  1.10011527,  0.15521095, -1.55631686,\n",
       "         0.73586292, -0.15641711, -0.50069625, -0.12249976, -0.04209096,\n",
       "         0.00383228,  0.16119416,  0.12092417,  0.11394671, -0.23443516,\n",
       "        -0.18259502,  0.18303074]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Coefficients or Model Weights/Parameters for each of the inputs. Allows to see the impact of each input\n",
    "model_lr_1.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the Model\n",
    "\n",
    "##### Hyperparameter Optimization \n",
    "Allows us to use the model that has the best combination of parameters\n",
    "\n",
    "##### K-Fold Cross Validation\n",
    "Technique to improve model by using a cross validation set to build the best model then only test on the test dataset one time. Train data split into 3(folds), 1 for testing one for training and get a score. Then a different split of 3 is used to get a score. This method will help reduce the chances of over/underfitting\n",
    "\n",
    "##### Feature Normalization and Standardization\n",
    "Most algorithms perform better if the features are on the same scale like 0 to 1. Specifically Standardization is able to account for the distribution of each feature by ensuring that along with the 0 to 1 scale the mean is made to be 0 and the variance 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization + Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Creating a model\n",
    "model_lr = LogisticRegression(random_state = 0, max_iter = 5000) # 5000 to remove max iter error\n",
    "\n",
    "# Creating parameters to try in the process\n",
    "parameters = {'C' : [1.0, 10.0, 50.0, 100.0, 1000.0],\n",
    "'penalty' : ['l1', 'l2'],\n",
    "'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "\n",
    "# Here the model is designed with the parameters that will be iterated through as well as the K = 3 cross validation\n",
    "# The train will be further split into 3 folds during this process\n",
    "clf = GridSearchCV(model_lr, param_grid = parameters, cv = 3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where C parameter controls how complex or over/underfit the regression is, cv is the cross validation used to come up with the optimal arrangement, n_jobs = -1  = run everything in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passing the train data to train different models with the parameter combinations specified above to find the best model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.83 Accuracy\n"
     ]
    }
   ],
   "source": [
    "# Prints the accuracy of the model with the best parameter arrangement\n",
    "print('Best Score: {:.2f} Accuracy'.format((clf.best_score_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much improvement but it is still best practice to perform this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the Logistic Regression V2: 0.83\n"
     ]
    }
   ],
   "source": [
    "# evalute model on test\n",
    "print('The accuracy for the Logistic Regression V2: {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Feature Normalization and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Normalization on the train data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Looking at min and max to check result\n",
    "X_train_scaled[:,0].min(), X_train_scaled[:,0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize test data features as well\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model After Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=5000, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=0, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [1.0, 10.0, 50.0, 100.0, 1000.0],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best model and perform cross validation with the standardized features\n",
    "model_lr = LogisticRegression(random_state = 0, max_iter = 5000) # 5000 to remove max iter error\n",
    "parameters = {'C' : [1.0, 10.0, 50.0, 100.0, 1000.0],\n",
    "'penalty' : ['l1', 'l2'],\n",
    "'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "\n",
    "clf = GridSearchCV(model_lr, param_grid = parameters, cv = 3)\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8132231795671855"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the Logistic Regression V3 after standardization: 0.84\n",
      "Confusion Matrix for the regression: \n",
      " [[106   4]\n",
      " [ 48  21]]\n",
      "Precision - how good the model is at predicting survivors: 0.84\n",
      "Recall - out of all survivors how many were predicted: 0.30\n",
      "\n",
      "\n",
      "Accuracy for the regression before standardization: 0.83\n",
      "Confusion Matrix for the regression: \n",
      " [[95 15]\n",
      " [15 54]]\n",
      "Precision - how good the model is at predicting survivors: 0.78\n",
      "Recall - out of all survivors how many were predicted: 0.78\n"
     ]
    }
   ],
   "source": [
    "# evalute model on test\n",
    "print('The accuracy for the Logistic Regression V3 after standardization: {:.2f}'.format(clf.score(X_test_scaled, y_test)))\n",
    "\n",
    "# Confusion Matrix\n",
    "print('Confusion Matrix for the regression: \\n {0}'.format(confusion_matrix(y_test, clf.predict(X_test))))\n",
    "\n",
    "# Precision and Recall scores\n",
    "print('Precision - how good the model is at predicting survivors: {:.2f}'.format(precision_score(y_test, clf.predict(X_test))))\n",
    "print('Recall - out of all survivors how many were predicted: {:.2f}\\n'.format(recall_score(y_test, clf.predict(X_test))))\n",
    "\n",
    "#Prior Result\n",
    "print('''\\nAccuracy for the regression before standardization: 0.83\\nConfusion Matrix for the regression: \n",
    " [[95 15]\n",
    " [15 54]]\n",
    "Precision - how good the model is at predicting survivors: 0.78\n",
    "Recall - out of all survivors how many were predicted: 0.78''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization usually does not have a large affect on Logistic Regression Models. With the slight increase in accuracy there was a drop in Recall to 30% but an increase in Precision to 84%. With that the Logistic Regression Model has being optimized to predict the survivors of the Titantic with accuracy of 84%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Persistance\n",
    "To make the model resuable to use whenever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# file path to put model\n",
    "model_file_path = r'C:\\Users\\Owner\\Desktop\\School\\Prog in Pyth C996\\Notebooks\\lr_model.pkl'\n",
    "scaler_file_path = r'C:\\Users\\Owner\\Desktop\\School\\Prog in Pyth C996\\Notebooks\\lr_scaler.pkl'\n",
    "\n",
    "# open the files to write\n",
    "model_file_pickle = open(model_file_path, 'wb')\n",
    "scaler_file_pickle = open(scaler_file_path, 'wb')\n",
    "\n",
    "# Persist the model \n",
    "pickle.dump(clf, model_file_pickle)\n",
    "pickle.dump(scaler, scaler_file_pickle)\n",
    "\n",
    "# Close the file\n",
    "model_file_pickle.close()\n",
    "scaler_file_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening in read mode\n",
    "model_file_pickle = open(model_file_path, 'rb')\n",
    "scaler_file_pickle = open(scaler_file_path, 'rb')\n",
    "\n",
    "# loading file\n",
    "clf_loaded = pickle.load(model_file_pickle)\n",
    "scaler_loaded = pickle.load(scaler_file_pickle)\n",
    "\n",
    "# close\n",
    "model_file_pickle.close()\n",
    "scaler_file_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=5000, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=0, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [1.0, 10.0, 50.0, 100.0, 1000.0],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to see if we can see the log reg classifier\n",
    "clf_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to see of the scaler is there\n",
    "scaler_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Final Test\n",
    "Now we can finally test the fully functional algorithm on the test data we read in at the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data into numeric\n",
    "X_f_test = test_df.to_numpy(dtype = 'float')\n",
    "# Scaling the data with the loaded scaler object to get the 0 to 1 ranges\n",
    "X_f_test_scaled = scaler_loaded.transform(X_f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the suvivors of the test data csv\n",
    "\n",
    "y_f = clf_loaded.predict(X_f_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have predictions for the 418 entries in the final test csv\n",
    "len(y_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 247, 1: 171}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_f, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can see the results of the model on unknown data where the actual values are not known. Because of this there is no way to check the accuracy of this output. The model predicted when looking at 418 instances that 171 would be survivors and 247 would unfortunately not survive, a survival rate of ~40%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
