---
title: "K-Means Clustering"
output: github_document
---

This notebook will be walking through the process of clustering the iris dataset by species. This will be done by showing support of statistical differences between groups and running a model to classify the groups

```{r}
# Installs
install.packages("cowplot")
install.packages("ggpubr")
```

```{r}
# Libraries
library(cowplot)
library(ggpubr)
```

A first look at the data shows signs of linear patterns in the data and more importantly signs of grouping. We can observe the four fields and three different flower species
```{r}
plot(iris)
```
Summary statistics for dataset
```{r}
summary(iris)
```
Looking at the two graphs below we can observe that species tend to group based on Sepal and Petal features
```{r}
par(mfrow=c(1,2))    # set the plotting area into a 1*2 array

# Plotting Sepal Length & Width by Species
ggscatter(iris, x = "Sepal.Length", y = "Sepal.Width",
          color = "Species", palette = "aaas",
          shape = "Species",
          ellipse = TRUE, ellipse.type = "convex")

# Plotting Petal Length & Width by Species
ggscatter(iris, x = "Petal.Length", y = "Petal.Width",
          color = "Species", palette = "aaas",
          shape = "Species",
          ellipse = TRUE, ellipse.type = "convex")

```
Now we'll use ANOVA to examine whether each feature is significantly different between each species. It turns out the species have significant differences in all features. More specifically the test states that at least one pair of species is statistically different from one another for each flower feature. Next Tukey will be used to look at how exactly the species differ for each feature

```{r}
# Comparing Sepal length between species
sepal.length.aov <- aov(formula = Sepal.Length ~ Species, data = iris)
summary(sepal.length.aov)

# Comparing Sepal Width between species
sepal.width.aov <- aov(formula = Sepal.Width ~ Species, data = iris)
summary(sepal.width.aov)

# Comparing Petal length between species
petal.length.aov <- aov(formula = Petal.Length ~ Species, data = iris)
summary(petal.length.aov)

# Comparing Petal width between species
petal.width.aov <- aov(formula = Petal.Width ~ Species, data = iris)
summary(petal.width.aov)
```
Below we use Tukey to look into the differences between each species per feature based on the ANOVA tests ran previously. The output shows an estimation of the difference between averages between each species for each feature with 95% confidence i.e. The difference in sepal lengths between versicolor & setosa is 0.930 cm, with versicolor averaging 0.930 cm points higher with p adj = 0 meaning the difference is statistically significant. The 95% confidence interval of their difference is between 0.6862 and 1.1738 cms.
```{r}
TukeyHSD(x=sepal.length.aov, 'Species', conf.level=0.95)

TukeyHSD(x=sepal.width.aov, 'Species', conf.level=0.95)

TukeyHSD(x=petal.length.aov, 'Species', conf.level=0.95)

TukeyHSD(x=petal.width.aov, 'Species', conf.level=0.95)

```
Now we've supported the differences between each species with ANOVA we can now create a clustering model. The first step would be to normalize the data. Most algorithms work better with normalized data (scaling data to a range i.e. 0 to 1)

```{r}
# Separating data between variables and classes (species)
iris.new<- iris[,c(1,2,3,4)]
iris.class<- iris[,"Species"]

# Creating a function to normalize the data based on max min values of each col
normalize <- function(x){
  return (
    ( x-min(x) )/( max(x)-min(x) )
  )
}

iris.new$Sepal.Length<- normalize(iris.new$Sepal.Length)
iris.new$Sepal.Width<- normalize(iris.new$Sepal.Width)
iris.new$Petal.Length<- normalize(iris.new$Petal.Length)
iris.new$Petal.Width<- normalize(iris.new$Petal.Width)

# Check for range 0 to 1
summary(iris.new)
```
The K means model works by fitting data into a specified amount of groups "k". Plotting out the within cluster sum of squares (WSS) helps find the optimal amount for "k". The results show the sum of square differences basically flatten out with 3 groups, which makes sense with this data since there are only 3 flower species
```{r}
# Setting a seed to make results reproducile + Max K value
set.seed(5)
k.max <- 10

# Running the kmeans algorithm and getting the WSS values for k values from 1-10
wss <- sapply(1:k.max,function(k){
  kmeans(iris.new,k,nstart = 20,iter.max = 20)$tot.withinss
  })

plot(1:k.max,wss, type = "b", xlab = "Number of Clusters (k)", ylab = "WSS")
```
Now we run the model with k = 3 and plot the comparison to the original dataset. Visually the model seemed to do a good job at categorizing the flowers correctly. It has trouble classifying correctly in areas where versicolor and virginica meet

```{r}
results <- kmeans(iris.new, 3, nstart = 20)

par( mfrow=c(1,2) )

iris_clustered <- data.frame(iris, Cluster=factor(results$cluster))

ggscatter(iris_clustered, x = "Sepal.Length", y = "Sepal.Width",
          color = "Cluster",
          palette = "aaas",
          shape = "Species"
          )

ggscatter(iris_clustered, x = "Petal.Length", y = "Petal.Width",
          color = "Cluster",
          palette = "aaas",
          shape = "Species"
          )
```
As noticed in the graph the model incorrectly classified a few Virgincas (14) and a couple Versicolos (3), but correctly classified all Setosas. With a total of 133 correct classifications the accuracy of the model was 88.7%. If a higher accuracy is desired different K values or potentially different algorithms like k-NN or SVM could possibly yield better results.

```{r}
# Results shown below where 1 = Setosa, 2 = Versicolor, 3 = Virginica
table(iris_clustered$Cluster,iris_clustered$Species)
```



